{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44db54b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import quote, urlencode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c925d25",
   "metadata": {},
   "source": [
    "You can find detailed docummentation about retrieving ArXive data via their REST API here: https://info.arxiv.org/help/api/user-manual.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5fccf",
   "metadata": {},
   "source": [
    "#### URL for querying ArXiv papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafa9641",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://export.arxiv.org/api/query\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f347fab",
   "metadata": {},
   "source": [
    "#### Compose a Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a117d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_filter = \"cat:cs.AI\"\n",
    "date_filter = \"submittedDate:[202501010000+TO+202510012359]\"\n",
    "search_query = f\"{category_filter} AND {date_filter}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2494a87",
   "metadata": {},
   "source": [
    "#### Configure other parameters and transform them into a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23e9944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"search_query\": search_query,\n",
    "    \"start\": 0,\n",
    "    \"max_results\": 20,\n",
    "}\n",
    "query = urlencode(params, quote_via=quote, safe=\":+[]*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ed7f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'search_query=cat:cs.AI%20AND%20submittedDate:[202501010000+TO+202510012359]&start=0&max_results=20'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648905d9",
   "metadata": {},
   "source": [
    "#### Construct a URL for a GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8564799",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_url = f\"{BASE_URL}?{query}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74573519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://export.arxiv.org/api/query?search_query=cat:cs.AI%20AND%20submittedDate:[202501010000+TO+202510012359]&start=0&max_results=20'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37180d7b",
   "metadata": {},
   "source": [
    "#### Execute the GET request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4e5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(get_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb684786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
      "<feed xmlns=\"http://www.w3.org/2005/Atom\">\n",
      "  <link href=\"http://arxiv.org/api/query?search_query%3Dcat%3Acs.AI%20AND%20submittedDate%3A%5B202501010000%20TO%20202510012359%5D%26id_list%3D%26start%3D0%26max_results%3D20\" rel=\"self\" type=\"application/atom+xml\"/>\n",
      "  <title type=\"html\">ArXiv Query: search_query=cat:cs.AI AND submittedDate:[202501010000 TO 202510012359]&amp;id_list=&amp;start=0&amp;max_results=20</title>\n",
      "  <id>http://arxiv.org/api/ZKR0lfoX03mB3UXQnPZDo8ddvV4</id>\n",
      "  <updated>2025-10-27T00:00:00-04:00</updated>\n",
      "  <opensearch:totalResults xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">33121</opensearch:totalResults>\n",
      "  <opensearch:startIndex xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">0</opensearch:startIndex>\n",
      "  <opensearch:itemsPerPage xmlns:opensearch=\"http://a9.com/-/spec/opensearch/1.1/\">20</opensearch:itemsPerPage>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.00750v2</id>\n",
      "    <updated>2025-01-29T06:49:30Z</updated>\n",
      "    <published>2025-01-01T06:36:56Z</published>\n",
      "    <title>Beyond Text: Implementing Multimodal Large Language Model-Powered\n",
      "  Multi-Agent Systems Using a No-Code Platform</title>\n",
      "    <summary>  This study proposes the design and implementation of a multimodal LLM-based\n",
      "Multi-Agent System (MAS) leveraging a No-Code platform to address the practical\n",
      "constraints and significant entry barriers associated with AI adoption in\n",
      "enterprises. Advanced AI technologies, such as Large Language Models (LLMs),\n",
      "often pose challenges due to their technical complexity and high implementation\n",
      "costs, making them difficult for many organizations to adopt. To overcome these\n",
      "limitations, this research develops a No-Code-based Multi-Agent System designed\n",
      "to enable users without programming knowledge to easily build and manage AI\n",
      "systems. The study examines various use cases to validate the applicability of\n",
      "AI in business processes, including code generation from image-based notes,\n",
      "Advanced RAG-based question-answering systems, text-based image generation, and\n",
      "video generation using images and prompts. These systems lower the barriers to\n",
      "AI adoption, empowering not only professional developers but also general users\n",
      "to harness AI for significantly improved productivity and efficiency. By\n",
      "demonstrating the scalability and accessibility of No-Code platforms, this\n",
      "study advances the democratization of AI technologies within enterprises and\n",
      "validates the practical applicability of Multi-Agent Systems, ultimately\n",
      "contributing to the widespread adoption of AI across various industries.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Cheonsu Jeong</name>\n",
      "    </author>\n",
      "    <arxiv:doi xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10.13088/jiis.2025.31.1.191</arxiv:doi>\n",
      "    <link title=\"doi\" href=\"http://dx.doi.org/10.13088/jiis.2025.31.1.191\" rel=\"related\"/>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 27 figures</arxiv:comment>\n",
      "    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">2025 Journal of Intelligence and Information Systems</arxiv:journal_ref>\n",
      "    <link href=\"http://arxiv.org/abs/2501.00750v2\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.00750v2\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.01149v2</id>\n",
      "    <updated>2025-02-18T08:24:59Z</updated>\n",
      "    <published>2025-01-02T09:03:56Z</published>\n",
      "    <title>A3: Android Agent Arena for Mobile GUI Agents</title>\n",
      "    <summary>  AI agents have become increasingly prevalent in recent years, driven by\n",
      "significant advancements in the field of large language models (LLMs). Mobile\n",
      "GUI agents, a subset of AI agents, are designed to autonomously perform tasks\n",
      "on mobile devices. While numerous studies have introduced agents, datasets, and\n",
      "benchmarks to advance mobile GUI agent research, many existing datasets focus\n",
      "on static frame evaluations and fail to provide a comprehensive platform for\n",
      "assessing performance on real-world, in-the-wild tasks. To address this gap, we\n",
      "present Android Agent Arena (A3), a novel evaluation platform. Unlike existing\n",
      "in-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as\n",
      "real-time online information retrieval and operational instructions; (2) a\n",
      "larger, more flexible action space, enabling compatibility with agents trained\n",
      "on any dataset; and (3) automated business-level LLM-based evaluation process.\n",
      "A3 includes 21 widely used general third-party apps and 201 tasks\n",
      "representative of common user scenarios, providing a robust foundation for\n",
      "evaluating mobile GUI agents in real-world situations and a new autonomous\n",
      "evaluation process for less human labor and coding expertise. The project is\n",
      "available at https://yuxiangchai.github.io/Android-Agent-Arena/.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Yuxiang Chai</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Hanhao Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jiayu Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Liang Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Guangyi Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Guozhi Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Shuai Ren</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Siyuan Huang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Hongsheng Li</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.01149v2\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.01149v2\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.01349v1</id>\n",
      "    <updated>2025-01-02T17:01:06Z</updated>\n",
      "    <published>2025-01-02T17:01:06Z</published>\n",
      "    <title>Rethinking Relation Extraction: Beyond Shortcuts to Generalization with\n",
      "  a Debiased Benchmark</title>\n",
      "    <summary>  Benchmarks are crucial for evaluating machine learning algorithm performance,\n",
      "facilitating comparison and identifying superior solutions. However, biases\n",
      "within datasets can lead models to learn shortcut patterns, resulting in\n",
      "inaccurate assessments and hindering real-world applicability. This paper\n",
      "addresses the issue of entity bias in relation extraction tasks, where models\n",
      "tend to rely on entity mentions rather than context. We propose a debiased\n",
      "relation extraction benchmark DREB that breaks the pseudo-correlation between\n",
      "entity mentions and relation types through entity replacement. DREB utilizes\n",
      "Bias Evaluator and PPL Evaluator to ensure low bias and high naturalness,\n",
      "providing a reliable and accurate assessment of model generalization in entity\n",
      "bias scenarios. To establish a new baseline on DREB, we introduce MixDebias, a\n",
      "debiasing method combining data-level and model training-level techniques.\n",
      "MixDebias effectively improves model performance on DREB while maintaining\n",
      "performance on the original dataset. Extensive experiments demonstrate the\n",
      "effectiveness and robustness of MixDebias compared to existing methods,\n",
      "highlighting its potential for improving the generalization ability of relation\n",
      "extraction models. We will release DREB and MixDebias publicly.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Liang He</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yougang Chu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Zhen Wu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jianbing Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xinyu Dai</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jiajun Chen</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.01349v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.01349v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.01835v1</id>\n",
      "    <updated>2025-01-03T14:38:03Z</updated>\n",
      "    <published>2025-01-03T14:38:03Z</published>\n",
      "    <title>ASKCOS: an open source software suite for synthesis planning</title>\n",
      "    <summary>  The advancement of machine learning and the availability of large-scale\n",
      "reaction datasets have accelerated the development of data-driven models for\n",
      "computer-aided synthesis planning (CASP) in the past decade. Here, we detail\n",
      "the newest version of ASKCOS, an open source software suite for synthesis\n",
      "planning that makes available several research advances in a freely available,\n",
      "practical tool. Four one-step retrosynthesis models form the basis of both\n",
      "interactive planning and automatic planning modes. Retrosynthetic planning is\n",
      "complemented by other modules for feasibility assessment and pathway\n",
      "evaluation, including reaction condition recommendation, reaction outcome\n",
      "prediction, and auxiliary capabilities such as solubility prediction and\n",
      "quantum mechanical descriptor prediction. ASKCOS has assisted hundreds of\n",
      "medicinal, synthetic, and process chemists in their day-to-day tasks,\n",
      "complementing expert decision making. It is our belief that CASP tools like\n",
      "ASKCOS are an important part of modern chemistry research, and that they offer\n",
      "ever-increasing utility and accessibility.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Zhengkai Tu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Sourabh J. Choure</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mun Hong Fong</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jihye Roh</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Itai Levin</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Kevin Yu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Joonyoung F. Joung</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Nathan Morgan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Shih-Cheng Li</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xiaoqi Sun</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Huiqian Lin</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mark Murnin</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jordan P. Liles</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Thomas J. Struble</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Michael E. Fortunato</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mengjie Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>William H. Green</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Klavs F. Jensen</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Connor W. Coley</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.01835v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.01835v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.02725v4</id>\n",
      "    <updated>2025-06-27T18:52:13Z</updated>\n",
      "    <published>2025-01-06T02:46:33Z</published>\n",
      "    <title>Artificial Intelligence in Creative Industries: Advances Prior to 2025</title>\n",
      "    <summary>  The rapid advancements in artificial intelligence (AI), particularly in\n",
      "generative AI and large language models (LLMs), have profoundly impacted the\n",
      "creative industries, enabling more innovative content creation, enhancing\n",
      "workflows, and democratizing access to creative tools. This paper explores\n",
      "these technological shifts, with particular focus on how those that have\n",
      "emerged since our previous review in 2022 have expanded creative opportunities\n",
      "and improved efficiency. These technological advancements have enhanced the\n",
      "capabilities of text-to-image, text-to-video, and multimodal generation\n",
      "technologies. In particular, key breakthroughs in LLMs have established new\n",
      "benchmarks in conversational AI, while advancements in image generators have\n",
      "revolutionized content creation. We also discuss the integration of AI into\n",
      "post-production workflows, which has significantly accelerated and improved\n",
      "traditional processes. Once content has been created, it must be delivered to\n",
      "its audiences; the media industry is now facing the demands of increased\n",
      "communication traffic due to creative content. We therefore include a\n",
      "discussion of how AI is beginning to transform the way we represent and\n",
      "compress media content. We highlight the trend toward unified AI frameworks\n",
      "capable of addressing and integrating multiple creative tasks, and we\n",
      "underscore the importance of human insight to drive the creative process and\n",
      "oversight to mitigate AI-generated inaccuracies. Finally, we explore AI's\n",
      "future potential in the creative sector, stressing the need to navigate\n",
      "emerging challenges and to maximize its benefits while addressing the\n",
      "associated risks.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Nantheera Anantrasirichai</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Fan Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>David Bull</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">This is an updated review of our previous paper (see\n",
      "  https://doi.org/10.1007/s10462-021-10039-7)</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2501.02725v4\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.02725v4\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.03824v1</id>\n",
      "    <updated>2025-01-07T14:36:33Z</updated>\n",
      "    <published>2025-01-07T14:36:33Z</published>\n",
      "    <title>Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function\n",
      "  for Real-Time Strategy Tasks</title>\n",
      "    <summary>  Effective evaluation of real-time strategy tasks requires adaptive mechanisms\n",
      "to cope with dynamic and unpredictable environments. This study proposes a\n",
      "method to improve evaluation functions for real-time responsiveness to\n",
      "battle-field situation changes, utilizing an online reinforcement\n",
      "learning-based dynam-ic weight adjustment mechanism within the real-time\n",
      "strategy game. Building on traditional static evaluation functions, the method\n",
      "employs gradient descent in online reinforcement learning to update weights\n",
      "dynamically, incorporating weight decay techniques to ensure stability.\n",
      "Additionally, the AdamW optimizer is integrated to adjust the learning rate and\n",
      "decay rate of online reinforcement learning in real time, further reducing the\n",
      "dependency on manual parameter tun-ing. Round-robin competition experiments\n",
      "demonstrate that this method signifi-cantly enhances the application\n",
      "effectiveness of the Lanchester combat model evaluation function, Simple\n",
      "evaluation function, and Simple Sqrt evaluation function in planning algorithms\n",
      "including IDABCD, IDRTMinimax, and Port-folio AI. The method achieves a notable\n",
      "improvement in scores, with the en-hancement becoming more pronounced as the\n",
      "map size increases. Furthermore, the increase in evaluation function\n",
      "computation time induced by this method is kept below 6% for all evaluation\n",
      "functions and planning algorithms. The pro-posed dynamic adaptive evaluation\n",
      "function demonstrates a promising approach for real-time strategy task\n",
      "evaluation.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Weilong Yang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jie Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xunyun Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yanqing Ye</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 9 figures</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2501.03824v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.03824v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.05435v2</id>\n",
      "    <updated>2025-04-05T23:53:49Z</updated>\n",
      "    <published>2025-01-09T18:48:35Z</published>\n",
      "    <title>Neuro-Symbolic AI in 2024: A Systematic Review</title>\n",
      "    <summary>  Background: The field of Artificial Intelligence has undergone cyclical\n",
      "periods of growth and decline, known as AI summers and winters. Currently, we\n",
      "are in the third AI summer, characterized by significant advancements and\n",
      "commercialization, particularly in the integration of Symbolic AI and\n",
      "Sub-Symbolic AI, leading to the emergence of Neuro-Symbolic AI.\n",
      "  Methods: The review followed the PRISMA methodology, utilizing databases such\n",
      "as IEEE Explore, Google Scholar, arXiv, ACM, and SpringerLink. The inclusion\n",
      "criteria targeted peer-reviewed papers published between 2020 and 2024. Papers\n",
      "were screened for relevance to Neuro-Symbolic AI, with further inclusion based\n",
      "on the availability of associated codebases to ensure reproducibility.\n",
      "  Results: From an initial pool of 1,428 papers, 167 met the inclusion criteria\n",
      "and were analyzed in detail. The majority of research efforts are concentrated\n",
      "in the areas of learning and inference (63%), logic and reasoning (35%), and\n",
      "knowledge representation (44%). Explainability and trustworthiness are less\n",
      "represented (28%), with Meta-Cognition being the least explored area (5%). The\n",
      "review identifies significant interdisciplinary opportunities, particularly in\n",
      "integrating explainability and trustworthiness with other research areas.\n",
      "  Conclusion: Neuro-Symbolic AI research has seen rapid growth since 2020, with\n",
      "concentrated efforts in learning and inference. Significant gaps remain in\n",
      "explainability, trustworthiness, and Meta-Cognition. Addressing these gaps\n",
      "through interdisciplinary research will be crucial for advancing the field\n",
      "towards more intelligent, reliable, and context-aware AI systems.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Brandon C. Colelough</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>William Regli</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">19 pages</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2501.05435v2\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.05435v2\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06231v1</id>\n",
      "    <updated>2025-01-08T02:30:37Z</updated>\n",
      "    <published>2025-01-08T02:30:37Z</published>\n",
      "    <title>Sustainable and Intelligent Public Facility Failure Management System\n",
      "  Based on Large Language Models</title>\n",
      "    <summary>  This paper presents a new Large Language Model (LLM)-based Smart Device\n",
      "Management framework, a pioneering approach designed to address the intricate\n",
      "challenges of managing intelligent devices within public facilities, with a\n",
      "particular emphasis on applications to libraries. Our framework leverages\n",
      "state-of-the-art LLMs to analyze and predict device failures, thereby enhancing\n",
      "operational efficiency and reliability. Through prototype validation in\n",
      "real-world library settings, we demonstrate the framework's practical\n",
      "applicability and its capacity to significantly reduce budgetary constraints on\n",
      "public facilities. The advanced and innovative nature of our model is evident\n",
      "from its successful implementation in prototype testing. We plan to extend the\n",
      "framework's scope to include a wider array of public facilities and to\n",
      "integrate it with cutting-edge cybersecurity technologies, such as Internet of\n",
      "Things (IoT) security and machine learning algorithms for threat detection and\n",
      "response. This will result in a comprehensive and proactive maintenance system\n",
      "that not only bolsters the security of intelligent devices but also utilizes\n",
      "machine learning for automated analysis and real-time threat mitigation. By\n",
      "incorporating these advanced cybersecurity elements, our framework will be\n",
      "well-positioned to tackle the dynamic challenges of modern public\n",
      "infrastructure, ensuring robust protection against potential threats and\n",
      "enabling facilities to anticipate and prevent failures, leading to substantial\n",
      "cost savings and enhanced service quality.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Siguo Bi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jilong Zhang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Wei Ni</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06231v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06231v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06322v1</id>\n",
      "    <updated>2025-01-10T19:56:50Z</updated>\n",
      "    <published>2025-01-10T19:56:50Z</published>\n",
      "    <title>Multi-Agent Collaboration Mechanisms: A Survey of LLMs</title>\n",
      "    <summary>  With recent advances in Large Language Models (LLMs), Agentic AI has become\n",
      "phenomenal in real-world applications, moving toward multiple LLM-based agents\n",
      "to perceive, learn, reason, and act collaboratively. These LLM-based\n",
      "Multi-Agent Systems (MASs) enable groups of intelligent agents to coordinate\n",
      "and solve complex tasks collectively at scale, transitioning from isolated\n",
      "models to collaboration-centric approaches. This work provides an extensive\n",
      "survey of the collaborative aspect of MASs and introduces an extensible\n",
      "framework to guide future research. Our framework characterizes collaboration\n",
      "mechanisms based on key dimensions: actors (agents involved), types (e.g.,\n",
      "cooperation, competition, or coopetition), structures (e.g., peer-to-peer,\n",
      "centralized, or distributed), strategies (e.g., role-based or model-based), and\n",
      "coordination protocols. Through a review of existing methodologies, our\n",
      "findings serve as a foundation for demystifying and advancing LLM-based MASs\n",
      "toward more intelligent and collaborative solutions for complex, real-world use\n",
      "cases. In addition, various applications of MASs across diverse domains,\n",
      "including 5G/6G networks, Industry 5.0, question answering, and social and\n",
      "cultural settings, are also investigated, demonstrating their wider adoption\n",
      "and broader impacts. Finally, we identify key lessons learned, open challenges,\n",
      "and potential research directions of MASs towards artificial collective\n",
      "intelligence.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Khanh-Tung Tran</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Dung Dao</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Minh-Duong Nguyen</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Quoc-Viet Pham</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Barry O'Sullivan</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Hoang D. Nguyen</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06322v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06322v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06423v1</id>\n",
      "    <updated>2025-01-11T03:29:14Z</updated>\n",
      "    <published>2025-01-11T03:29:14Z</published>\n",
      "    <title>AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written\n",
      "  Programs</title>\n",
      "    <summary>  Program synthesis has traditionally relied on human-provided specifications,\n",
      "examples, or prior knowledge to generate functional algorithms. Existing\n",
      "methods either emulate human-written algorithms or solve specific tasks without\n",
      "generating reusable programmatic logic, limiting their ability to create novel\n",
      "algorithms. We introduce AlgoPilot, a groundbreaking approach for fully\n",
      "automated program synthesis without human-written programs or trajectories.\n",
      "AlgoPilot leverages reinforcement learning (RL) guided by a Trajectory Language\n",
      "Model (TLM) to synthesize algorithms from scratch. The TLM, trained on\n",
      "trajectories generated by random Python functions, serves as a soft constraint\n",
      "during the RL process, aligning generated sequences with patterns likely to\n",
      "represent valid algorithms. Using sorting as a test case, AlgoPilot\n",
      "demonstrates its ability to generate trajectories that are interpretable as\n",
      "classical algorithms, such as Bubble Sort, while operating without prior\n",
      "algorithmic knowledge. This work establishes a new paradigm for algorithm\n",
      "discovery and lays the groundwork for future advancements in autonomous program\n",
      "synthesis.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Xiaoxin Yin</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06423v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06423v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06442v1</id>\n",
      "    <updated>2025-01-11T05:44:33Z</updated>\n",
      "    <published>2025-01-11T05:44:33Z</published>\n",
      "    <title>ARES: Auxiliary Range Expansion for Outlier Synthesis</title>\n",
      "    <summary>  Recent successes of artificial intelligence and deep learning often depend on\n",
      "the well-collected training dataset which is assumed to have an identical\n",
      "distribution with the test dataset. However, this assumption, which is called\n",
      "closed-set learning, is hard to meet in realistic scenarios for deploying deep\n",
      "learning models. As one of the solutions to mitigate this assumption, research\n",
      "on out-of-distribution (OOD) detection has been actively explored in various\n",
      "domains. In OOD detection, we assume that we are given the data of a new class\n",
      "that was not seen in the training phase, i.e., outlier, at the evaluation\n",
      "phase. The ultimate goal of OOD detection is to detect and classify such unseen\n",
      "outlier data as a novel \"unknown\" class. Among various research branches for\n",
      "OOD detection, generating a virtual outlier during the training phase has been\n",
      "proposed. However, conventional generation-based methodologies utilize\n",
      "in-distribution training dataset to imitate outlier instances, which limits the\n",
      "quality of the synthesized virtual outlier instance itself. In this paper, we\n",
      "propose a novel methodology for OOD detection named Auxiliary Range Expansion\n",
      "for Outlier Synthesis, or ARES. ARES models the region for generating\n",
      "out-of-distribution instances by escaping from the given in-distribution\n",
      "region; instead of remaining near the boundary of in-distribution region.\n",
      "Various stages consists ARES to ultimately generate valuable OOD-like virtual\n",
      "instances. The energy score-based discriminator is then trained to effectively\n",
      "separate in-distribution data and outlier data. Quantitative experiments on\n",
      "broad settings show the improvement of performance by our method, and\n",
      "qualitative results provide logical explanations of the mechanism behind it.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Eui-Soo Jung</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Hae-Hun Seo</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Hyun-Woo Jung</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Je-Geon Oh</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yoon-Yeong Kim</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06442v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06442v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06461v1</id>\n",
      "    <updated>2025-01-11T07:18:12Z</updated>\n",
      "    <published>2025-01-11T07:18:12Z</published>\n",
      "    <title>Assessing instructor-AI cooperation for grading essay-type questions in\n",
      "  an introductory sociology course</title>\n",
      "    <summary>  This study explores the use of artificial intelligence (AI) as a\n",
      "complementary tool for grading essay-type questions in higher education,\n",
      "focusing on its consistency with human grading and potential to reduce biases.\n",
      "Using 70 handwritten exams from an introductory sociology course, we evaluated\n",
      "generative pre-trained transformers (GPT) models' performance in transcribing\n",
      "and scoring students' responses. GPT models were tested under various settings\n",
      "for both transcription and grading tasks. Results show high similarity between\n",
      "human and GPT transcriptions, with GPT-4o-mini outperforming GPT-4o in\n",
      "accuracy. For grading, GPT demonstrated strong correlations with the human\n",
      "grader scores, especially when template answers were provided. However,\n",
      "discrepancies remained, highlighting GPT's role as a \"second grader\" to flag\n",
      "inconsistencies for assessment reviewing rather than fully replace human\n",
      "evaluation. This study contributes to the growing literature on AI in\n",
      "education, demonstrating its potential to enhance fairness and efficiency in\n",
      "grading essay-type questions.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Francisco Olivos</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Tobias Kamelski</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Sebasti√°n Ascui-Gac</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">10 figures, 2 tables</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06461v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06461v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06471v1</id>\n",
      "    <updated>2025-01-11T08:00:24Z</updated>\n",
      "    <published>2025-01-11T08:00:24Z</published>\n",
      "    <title>The Internet of Large Language Models: An Orchestration Framework for\n",
      "  LLM Training and Knowledge Exchange Toward Artificial General Intelligence</title>\n",
      "    <summary>  This paper explores the multi-dimensional challenges faced during the\n",
      "development of Large Language Models (LLMs), including the massive scale of\n",
      "model parameters and file sizes, the complexity of development environment\n",
      "configuration, the singularity of model functionality, and the high costs of\n",
      "computational resources. To address these challenges, this paper proposes three\n",
      "core technical solutions: LLM sharing protocol, LLM universal environment\n",
      "framework, and Agent optimal path module. To solve the computational resource\n",
      "constraints in the early stages of research, we further innovatively propose a\n",
      "joint mining mechanism, achieving bilateral value sharing between computing\n",
      "power providers and model designers, including breakthrough rewards for optimal\n",
      "model paths and long-term profit distribution, thereby providing researchers\n",
      "with cost-optimized computational resource support and promoting the continuous\n",
      "development of LLM research and applications.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Wilson Wei</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Nicholas Chen</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yuxuan Li</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06471v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06471v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06485v1</id>\n",
      "    <updated>2025-01-11T08:39:33Z</updated>\n",
      "    <published>2025-01-11T08:39:33Z</published>\n",
      "    <title>A Diffusive Data Augmentation Framework for Reconstruction of Complex\n",
      "  Network Evolutionary History</title>\n",
      "    <summary>  The evolutionary processes of complex systems contain critical information\n",
      "regarding their functional characteristics. The generation time of edges\n",
      "provides insights into the historical evolution of various networked complex\n",
      "systems, such as protein-protein interaction networks, ecosystems, and social\n",
      "networks. Recovering these evolutionary processes holds significant scientific\n",
      "value, including aiding in the interpretation of the evolution of\n",
      "protein-protein interaction networks. However, existing methods are capable of\n",
      "predicting the generation times of remaining edges given a partial temporal\n",
      "network but often perform poorly in cross-network prediction tasks. These\n",
      "methods frequently fail in edge generation time recovery tasks for static\n",
      "networks that lack timestamps. In this work, we adopt a comparative\n",
      "paradigm-based framework that fuses multiple networks for training, enabling\n",
      "cross-network learning of the relationship between network structure and edge\n",
      "generation times. Compared to separate training, this approach yields an\n",
      "average accuracy improvement of 16.98%. Furthermore, given the difficulty in\n",
      "collecting temporal networks, we propose a novel diffusion-model-based\n",
      "generation method to produce a large number of temporal networks. By combining\n",
      "real temporal networks with generated ones for training, we achieve an\n",
      "additional average accuracy improvement of 5.46% through joint training.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>En Xu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Can Rong</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Jingtao Ding</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yong Li</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06485v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06485v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06561v2</id>\n",
      "    <updated>2025-08-19T14:26:55Z</updated>\n",
      "    <published>2025-01-11T14:41:47Z</published>\n",
      "    <title>Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for\n",
      "  Mid-term Human Mobility Prediction</title>\n",
      "    <summary>  Predicting individual mobility patterns is crucial across various\n",
      "applications. While current methods mainly focus on predicting the next\n",
      "location for personalized services like recommendations, they often fall short\n",
      "in supporting broader applications such as traffic management and epidemic\n",
      "control, which require longer period forecasts of human mobility. This study\n",
      "addresses mid-term mobility prediction, aiming to capture daily travel patterns\n",
      "and forecast trajectories for the upcoming day or week. We propose a novel\n",
      "Multi-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to\n",
      "efficiently extract spatial and temporal information by decoupling daily\n",
      "trajectories into distinct location-duration chains. Our approach employs a\n",
      "hierarchical encoder to model multi-scale temporal patterns, including daily\n",
      "recurrence and weekly periodicity, and utilizes a transformer-based decoder to\n",
      "globally attend to predicted information in the location or duration chain.\n",
      "Additionally, we introduce a spatial heterogeneous graph learner to capture\n",
      "multi-scale spatial relationships, enhancing semantic-rich representations.\n",
      "Extensive experiments, including statistical physics analysis, are conducted on\n",
      "large-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay\n",
      "Area, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to\n",
      "epidemic modeling in Boston, MSTDP significantly outperforms the\n",
      "best-performing baseline, achieving a remarkable 62.8% reduction in MAE for\n",
      "cumulative new cases.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Zongyuan Huang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Weipeng Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Shaoyu Huang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Marta C. Gonzalez</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yaohui Jin</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Yanyan Xu</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06561v2\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06561v2\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06577v1</id>\n",
      "    <updated>2025-01-11T16:01:44Z</updated>\n",
      "    <published>2025-01-11T16:01:44Z</published>\n",
      "    <title>Transforming Social Science Research with Transfer Learning: Social\n",
      "  Science Survey Data Integration with AI</title>\n",
      "    <summary>  Large-N nationally representative surveys, which have profoundly shaped\n",
      "American politics scholarship, represent related but distinct domains -a key\n",
      "condition for transfer learning applications. These surveys are related through\n",
      "their shared demographic, party identification, and ideological variables, yet\n",
      "differ in that individual surveys often lack specific policy preference\n",
      "questions that researchers require. Our study introduces a novel application of\n",
      "transfer learning (TL) to address these gaps, marking the first systematic use\n",
      "of TL paradigms in the context of survey data. Specifically, models pre-trained\n",
      "on the Cooperative Election Study (CES) dataset are fine-tuned for use in the\n",
      "American National Election Studies (ANES) dataset to predict policy questions\n",
      "based on demographic variables. Even with a naive architecture, our transfer\n",
      "learning approach achieves approximately 92 percentage accuracy in predicting\n",
      "missing variables across surveys, demonstrating the robust potential of this\n",
      "method. Beyond this specific application, our paper argues that transfer\n",
      "learning is a promising framework for maximizing the utility of existing survey\n",
      "data. We contend that artificial intelligence, particularly transfer learning,\n",
      "opens new frontiers in social science methodology by enabling systematic\n",
      "knowledge transfer between well-administered surveys that share common\n",
      "variables but differ in their outcomes of interest.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Ali Amini</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">22 pages, 5 figures, Presented and Submitted to SPSA 2025 (Political\n",
      "  Methodology Panel)</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06577v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06577v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"I.2.7, I.2.6, H.1.2, I.2.10\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06598v3</id>\n",
      "    <updated>2025-07-02T04:47:37Z</updated>\n",
      "    <published>2025-01-11T17:52:22Z</published>\n",
      "    <title>ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code\n",
      "  Generation</title>\n",
      "    <summary>  Multimodal Large Language Models (MLLMs) have demonstrated remarkable\n",
      "capabilities in chart understanding tasks. However, interpreting charts with\n",
      "textual descriptions often leads to information loss, as it fails to fully\n",
      "capture the dense information embedded in charts. In contrast, parsing charts\n",
      "into code provides lossless representations that can effectively contain all\n",
      "critical details. Although existing open-source MLLMs have achieved success in\n",
      "chart understanding tasks, they still face two major challenges when applied to\n",
      "chart-to-code tasks: (1) Low executability and poor restoration of chart\n",
      "details in the generated code and (2) Lack of large-scale and diverse training\n",
      "data. To address these challenges, we propose \\textbf{ChartCoder}, the first\n",
      "dedicated chart-to-code MLLM, which leverages Code LLMs as the language\n",
      "backbone to enhance the executability of the generated code. Furthermore, we\n",
      "introduce \\textbf{Chart2Code-160k}, the first large-scale and diverse dataset\n",
      "for chart-to-code generation, and propose the \\textbf{Snippet-of-Thought (SoT)}\n",
      "method, which transforms direct chart-to-code generation data into step-by-step\n",
      "generation. Experiments demonstrate that ChartCoder, with only 7B parameters,\n",
      "surpasses existing open-source MLLMs on chart-to-code benchmarks, achieving\n",
      "superior chart restoration and code excitability. Our code is available at\n",
      "https://github.com/thunlp/ChartCoder.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Xuanle Zhao</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Xianzhen Luo</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Qi Shi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Chi Chen</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Shuo Wang</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Zhiyuan Liu</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Maosong Sun</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Accepted by ACL 2025 Main, Camera Ready</arxiv:comment>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06598v3\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06598v3\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06625v1</id>\n",
      "    <updated>2025-01-11T19:21:53Z</updated>\n",
      "    <published>2025-01-11T19:21:53Z</published>\n",
      "    <title>Guided Code Generation with LLMs: A Multi-Agent Framework for Complex\n",
      "  Code Tasks</title>\n",
      "    <summary>  Large Language Models (LLMs) have shown remarkable capabilities in code\n",
      "generation tasks, yet they face significant limitations in handling complex,\n",
      "long-context programming challenges and demonstrating complex compositional\n",
      "reasoning abilities. This paper introduces a novel agentic framework for\n",
      "``guided code generation'' that tries to address these limitations through a\n",
      "deliberately structured, fine-grained approach to code generation tasks. Our\n",
      "framework leverages LLMs' strengths as fuzzy searchers and approximate\n",
      "information retrievers while mitigating their weaknesses in long sequential\n",
      "reasoning and long-context understanding. Empirical evaluation using OpenAI's\n",
      "HumanEval benchmark with Meta's Llama 3.1 8B model (int4 precision)\n",
      "demonstrates a 23.79\\% improvement in solution accuracy compared to direct\n",
      "one-shot generation. Our results indicate that structured, guided approaches to\n",
      "code generation can significantly enhance the practical utility of LLMs in\n",
      "software development while overcoming their inherent limitations in\n",
      "compositional reasoning and context handling.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Amr Almorsi</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Mohanned Ahmed</name>\n",
      "    </author>\n",
      "    <author>\n",
      "      <name>Walid Gomaa</name>\n",
      "    </author>\n",
      "    <arxiv:comment xmlns:arxiv=\"http://arxiv.org/schemas/atom\">4 pages, 3 figures</arxiv:comment>\n",
      "    <arxiv:journal_ref xmlns:arxiv=\"http://arxiv.org/schemas/atom\">Proceedings of the 2024 IEEE International Japan-Africa Conference\n",
      "  on Electronics communications and Computations (JAC ECC)</arxiv:journal_ref>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06625v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06625v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06628v1</id>\n",
      "    <updated>2025-01-11T19:50:09Z</updated>\n",
      "    <published>2025-01-11T19:50:09Z</published>\n",
      "    <title>Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs\n",
      "  with LLMs: A Neuro-Symbolic Approach</title>\n",
      "    <summary>  This paper introduces a neuro-symbolic approach for relational exploration in\n",
      "cultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for\n",
      "explanation generation and a novel mathematical framework to quantify the\n",
      "interestingness of relationships. We demonstrate the importance of\n",
      "interestingness measure using a quantitative analysis, by highlighting its\n",
      "impact on the overall performance of our proposed system, particularly in terms\n",
      "of precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked\n",
      "Open Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of\n",
      "0.68, and an F1-score of 0.69, representing an improvement compared to\n",
      "graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based\n",
      "baselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our\n",
      "LLM-powered explanations exhibit better quality, reflected in BLEU (0.52),\n",
      "ROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline\n",
      "approaches. We show a strong correlation (0.65) between interestingness measure\n",
      "and the quality of generated explanations, validating its effectiveness. The\n",
      "findings highlight the importance of LLMs and a mathematical formalization for\n",
      "interestingness in enhancing the effectiveness of relational exploration in\n",
      "cultural heritage knowledge graphs, with results that are measurable and\n",
      "testable. We further show that the system enables more effective exploration\n",
      "compared to purely knowledge-based and graph-based methods.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Mohammed Maree</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06628v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06628v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "  <entry>\n",
      "    <id>http://arxiv.org/abs/2501.06642v1</id>\n",
      "    <updated>2025-01-11T21:23:41Z</updated>\n",
      "    <published>2025-01-11T21:23:41Z</published>\n",
      "    <title>Common Sense Is All You Need</title>\n",
      "    <summary>  Artificial intelligence (AI) has made significant strides in recent years,\n",
      "yet it continues to struggle with a fundamental aspect of cognition present in\n",
      "all animals: common sense. Current AI systems, including those designed for\n",
      "complex tasks like autonomous driving, problem-solving challenges such as the\n",
      "Abstraction and Reasoning Corpus (ARC), and conversational benchmarks like the\n",
      "Turing Test, often lack the ability to adapt to new situations without\n",
      "extensive prior knowledge. This manuscript argues that integrating common sense\n",
      "into AI systems is essential for achieving true autonomy and unlocking the full\n",
      "societal and commercial value of AI.\n",
      "  We propose a shift in the order of knowledge acquisition emphasizing the\n",
      "importance of developing AI systems that start from minimal prior knowledge and\n",
      "are capable of contextual learning, adaptive reasoning, and embodiment -- even\n",
      "within abstract domains. Additionally, we highlight the need to rethink the AI\n",
      "software stack to address this foundational challenge. Without common sense, AI\n",
      "systems may never reach true autonomy, instead exhibiting asymptotic\n",
      "performance that approaches theoretical ideals like AIXI but remains\n",
      "unattainable in practice due to infinite resource and computation requirements.\n",
      "  While scaling AI models and passing benchmarks like the Turing Test have\n",
      "brought significant advancements in applications that do not require autonomy,\n",
      "these approaches alone are insufficient to achieve autonomous AI with common\n",
      "sense. By redefining existing benchmarks and challenges to enforce constraints\n",
      "that require genuine common sense, and by broadening our understanding of\n",
      "embodiment to include both physical and abstract domains, we can encourage the\n",
      "development of AI systems better equipped to handle the complexities of\n",
      "real-world and abstract environments.\n",
      "</summary>\n",
      "    <author>\n",
      "      <name>Hugo Latapie</name>\n",
      "    </author>\n",
      "    <link href=\"http://arxiv.org/abs/2501.06642v1\" rel=\"alternate\" type=\"text/html\"/>\n",
      "    <link title=\"pdf\" href=\"http://arxiv.org/pdf/2501.06642v1\" rel=\"related\" type=\"application/pdf\"/>\n",
      "    <arxiv:primary_category xmlns:arxiv=\"http://arxiv.org/schemas/atom\" term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "    <category term=\"cs.AI\" scheme=\"http://arxiv.org/schemas/atom\"/>\n",
      "  </entry>\n",
      "</feed>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c00748e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 33121\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# Parse the XML string\n",
    "root = ET.fromstring(response.text)\n",
    "\n",
    "# Define the namespace (arXiv uses Atom namespace)\n",
    "namespaces = {\n",
    "    'atom': 'http://www.w3.org/2005/Atom',\n",
    "    'opensearch': 'http://a9.com/-/spec/opensearch/1.1/',\n",
    "    'arxiv': 'http://arxiv.org/schemas/atom'\n",
    "}\n",
    "\n",
    "# Extract total results\n",
    "total_results = root.find('opensearch:totalResults', namespaces).text\n",
    "print(f\"Total results: {total_results}\")\n",
    "\n",
    "# Iterate through entries\n",
    "entries = root.findall('atom:entry', namespaces)\n",
    "\n",
    "papers = []\n",
    "for entry in entries:\n",
    "    paper = {\n",
    "        'id': entry.find('atom:id', namespaces).text,\n",
    "        'title': entry.find('atom:title', namespaces).text.strip(),\n",
    "        'summary': entry.find('atom:summary', namespaces).text.strip(),\n",
    "        'published': entry.find('atom:published', namespaces).text,\n",
    "        'updated': entry.find('atom:updated', namespaces).text,\n",
    "        'authors': [author.find('atom:name', namespaces).text \n",
    "                   for author in entry.findall('atom:author', namespaces)],\n",
    "        'pdf_link': entry.find(\"atom:link[@title='pdf']\", namespaces).get('href')\n",
    "    }\n",
    "    papers.append(paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa05a0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 'http://arxiv.org/abs/2501.00750v2',\n",
       "  'title': 'Beyond Text: Implementing Multimodal Large Language Model-Powered\\n  Multi-Agent Systems Using a No-Code Platform',\n",
       "  'summary': 'This study proposes the design and implementation of a multimodal LLM-based\\nMulti-Agent System (MAS) leveraging a No-Code platform to address the practical\\nconstraints and significant entry barriers associated with AI adoption in\\nenterprises. Advanced AI technologies, such as Large Language Models (LLMs),\\noften pose challenges due to their technical complexity and high implementation\\ncosts, making them difficult for many organizations to adopt. To overcome these\\nlimitations, this research develops a No-Code-based Multi-Agent System designed\\nto enable users without programming knowledge to easily build and manage AI\\nsystems. The study examines various use cases to validate the applicability of\\nAI in business processes, including code generation from image-based notes,\\nAdvanced RAG-based question-answering systems, text-based image generation, and\\nvideo generation using images and prompts. These systems lower the barriers to\\nAI adoption, empowering not only professional developers but also general users\\nto harness AI for significantly improved productivity and efficiency. By\\ndemonstrating the scalability and accessibility of No-Code platforms, this\\nstudy advances the democratization of AI technologies within enterprises and\\nvalidates the practical applicability of Multi-Agent Systems, ultimately\\ncontributing to the widespread adoption of AI across various industries.',\n",
       "  'published': '2025-01-01T06:36:56Z',\n",
       "  'updated': '2025-01-29T06:49:30Z',\n",
       "  'authors': ['Cheonsu Jeong'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.00750v2'},\n",
       " {'id': 'http://arxiv.org/abs/2501.01149v2',\n",
       "  'title': 'A3: Android Agent Arena for Mobile GUI Agents',\n",
       "  'summary': 'AI agents have become increasingly prevalent in recent years, driven by\\nsignificant advancements in the field of large language models (LLMs). Mobile\\nGUI agents, a subset of AI agents, are designed to autonomously perform tasks\\non mobile devices. While numerous studies have introduced agents, datasets, and\\nbenchmarks to advance mobile GUI agent research, many existing datasets focus\\non static frame evaluations and fail to provide a comprehensive platform for\\nassessing performance on real-world, in-the-wild tasks. To address this gap, we\\npresent Android Agent Arena (A3), a novel evaluation platform. Unlike existing\\nin-the-wild systems, A3 offers: (1) meaningful and practical tasks, such as\\nreal-time online information retrieval and operational instructions; (2) a\\nlarger, more flexible action space, enabling compatibility with agents trained\\non any dataset; and (3) automated business-level LLM-based evaluation process.\\nA3 includes 21 widely used general third-party apps and 201 tasks\\nrepresentative of common user scenarios, providing a robust foundation for\\nevaluating mobile GUI agents in real-world situations and a new autonomous\\nevaluation process for less human labor and coding expertise. The project is\\navailable at https://yuxiangchai.github.io/Android-Agent-Arena/.',\n",
       "  'published': '2025-01-02T09:03:56Z',\n",
       "  'updated': '2025-02-18T08:24:59Z',\n",
       "  'authors': ['Yuxiang Chai',\n",
       "   'Hanhao Li',\n",
       "   'Jiayu Zhang',\n",
       "   'Liang Liu',\n",
       "   'Guangyi Liu',\n",
       "   'Guozhi Wang',\n",
       "   'Shuai Ren',\n",
       "   'Siyuan Huang',\n",
       "   'Hongsheng Li'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.01149v2'},\n",
       " {'id': 'http://arxiv.org/abs/2501.01349v1',\n",
       "  'title': 'Rethinking Relation Extraction: Beyond Shortcuts to Generalization with\\n  a Debiased Benchmark',\n",
       "  'summary': 'Benchmarks are crucial for evaluating machine learning algorithm performance,\\nfacilitating comparison and identifying superior solutions. However, biases\\nwithin datasets can lead models to learn shortcut patterns, resulting in\\ninaccurate assessments and hindering real-world applicability. This paper\\naddresses the issue of entity bias in relation extraction tasks, where models\\ntend to rely on entity mentions rather than context. We propose a debiased\\nrelation extraction benchmark DREB that breaks the pseudo-correlation between\\nentity mentions and relation types through entity replacement. DREB utilizes\\nBias Evaluator and PPL Evaluator to ensure low bias and high naturalness,\\nproviding a reliable and accurate assessment of model generalization in entity\\nbias scenarios. To establish a new baseline on DREB, we introduce MixDebias, a\\ndebiasing method combining data-level and model training-level techniques.\\nMixDebias effectively improves model performance on DREB while maintaining\\nperformance on the original dataset. Extensive experiments demonstrate the\\neffectiveness and robustness of MixDebias compared to existing methods,\\nhighlighting its potential for improving the generalization ability of relation\\nextraction models. We will release DREB and MixDebias publicly.',\n",
       "  'published': '2025-01-02T17:01:06Z',\n",
       "  'updated': '2025-01-02T17:01:06Z',\n",
       "  'authors': ['Liang He',\n",
       "   'Yougang Chu',\n",
       "   'Zhen Wu',\n",
       "   'Jianbing Zhang',\n",
       "   'Xinyu Dai',\n",
       "   'Jiajun Chen'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.01349v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.01835v1',\n",
       "  'title': 'ASKCOS: an open source software suite for synthesis planning',\n",
       "  'summary': 'The advancement of machine learning and the availability of large-scale\\nreaction datasets have accelerated the development of data-driven models for\\ncomputer-aided synthesis planning (CASP) in the past decade. Here, we detail\\nthe newest version of ASKCOS, an open source software suite for synthesis\\nplanning that makes available several research advances in a freely available,\\npractical tool. Four one-step retrosynthesis models form the basis of both\\ninteractive planning and automatic planning modes. Retrosynthetic planning is\\ncomplemented by other modules for feasibility assessment and pathway\\nevaluation, including reaction condition recommendation, reaction outcome\\nprediction, and auxiliary capabilities such as solubility prediction and\\nquantum mechanical descriptor prediction. ASKCOS has assisted hundreds of\\nmedicinal, synthetic, and process chemists in their day-to-day tasks,\\ncomplementing expert decision making. It is our belief that CASP tools like\\nASKCOS are an important part of modern chemistry research, and that they offer\\never-increasing utility and accessibility.',\n",
       "  'published': '2025-01-03T14:38:03Z',\n",
       "  'updated': '2025-01-03T14:38:03Z',\n",
       "  'authors': ['Zhengkai Tu',\n",
       "   'Sourabh J. Choure',\n",
       "   'Mun Hong Fong',\n",
       "   'Jihye Roh',\n",
       "   'Itai Levin',\n",
       "   'Kevin Yu',\n",
       "   'Joonyoung F. Joung',\n",
       "   'Nathan Morgan',\n",
       "   'Shih-Cheng Li',\n",
       "   'Xiaoqi Sun',\n",
       "   'Huiqian Lin',\n",
       "   'Mark Murnin',\n",
       "   'Jordan P. Liles',\n",
       "   'Thomas J. Struble',\n",
       "   'Michael E. Fortunato',\n",
       "   'Mengjie Liu',\n",
       "   'William H. Green',\n",
       "   'Klavs F. Jensen',\n",
       "   'Connor W. Coley'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.01835v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.02725v4',\n",
       "  'title': 'Artificial Intelligence in Creative Industries: Advances Prior to 2025',\n",
       "  'summary': \"The rapid advancements in artificial intelligence (AI), particularly in\\ngenerative AI and large language models (LLMs), have profoundly impacted the\\ncreative industries, enabling more innovative content creation, enhancing\\nworkflows, and democratizing access to creative tools. This paper explores\\nthese technological shifts, with particular focus on how those that have\\nemerged since our previous review in 2022 have expanded creative opportunities\\nand improved efficiency. These technological advancements have enhanced the\\ncapabilities of text-to-image, text-to-video, and multimodal generation\\ntechnologies. In particular, key breakthroughs in LLMs have established new\\nbenchmarks in conversational AI, while advancements in image generators have\\nrevolutionized content creation. We also discuss the integration of AI into\\npost-production workflows, which has significantly accelerated and improved\\ntraditional processes. Once content has been created, it must be delivered to\\nits audiences; the media industry is now facing the demands of increased\\ncommunication traffic due to creative content. We therefore include a\\ndiscussion of how AI is beginning to transform the way we represent and\\ncompress media content. We highlight the trend toward unified AI frameworks\\ncapable of addressing and integrating multiple creative tasks, and we\\nunderscore the importance of human insight to drive the creative process and\\noversight to mitigate AI-generated inaccuracies. Finally, we explore AI's\\nfuture potential in the creative sector, stressing the need to navigate\\nemerging challenges and to maximize its benefits while addressing the\\nassociated risks.\",\n",
       "  'published': '2025-01-06T02:46:33Z',\n",
       "  'updated': '2025-06-27T18:52:13Z',\n",
       "  'authors': ['Nantheera Anantrasirichai', 'Fan Zhang', 'David Bull'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.02725v4'},\n",
       " {'id': 'http://arxiv.org/abs/2501.03824v1',\n",
       "  'title': 'Online Reinforcement Learning-Based Dynamic Adaptive Evaluation Function\\n  for Real-Time Strategy Tasks',\n",
       "  'summary': 'Effective evaluation of real-time strategy tasks requires adaptive mechanisms\\nto cope with dynamic and unpredictable environments. This study proposes a\\nmethod to improve evaluation functions for real-time responsiveness to\\nbattle-field situation changes, utilizing an online reinforcement\\nlearning-based dynam-ic weight adjustment mechanism within the real-time\\nstrategy game. Building on traditional static evaluation functions, the method\\nemploys gradient descent in online reinforcement learning to update weights\\ndynamically, incorporating weight decay techniques to ensure stability.\\nAdditionally, the AdamW optimizer is integrated to adjust the learning rate and\\ndecay rate of online reinforcement learning in real time, further reducing the\\ndependency on manual parameter tun-ing. Round-robin competition experiments\\ndemonstrate that this method signifi-cantly enhances the application\\neffectiveness of the Lanchester combat model evaluation function, Simple\\nevaluation function, and Simple Sqrt evaluation function in planning algorithms\\nincluding IDABCD, IDRTMinimax, and Port-folio AI. The method achieves a notable\\nimprovement in scores, with the en-hancement becoming more pronounced as the\\nmap size increases. Furthermore, the increase in evaluation function\\ncomputation time induced by this method is kept below 6% for all evaluation\\nfunctions and planning algorithms. The pro-posed dynamic adaptive evaluation\\nfunction demonstrates a promising approach for real-time strategy task\\nevaluation.',\n",
       "  'published': '2025-01-07T14:36:33Z',\n",
       "  'updated': '2025-01-07T14:36:33Z',\n",
       "  'authors': ['Weilong Yang', 'Jie Zhang', 'Xunyun Liu', 'Yanqing Ye'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.03824v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.05435v2',\n",
       "  'title': 'Neuro-Symbolic AI in 2024: A Systematic Review',\n",
       "  'summary': 'Background: The field of Artificial Intelligence has undergone cyclical\\nperiods of growth and decline, known as AI summers and winters. Currently, we\\nare in the third AI summer, characterized by significant advancements and\\ncommercialization, particularly in the integration of Symbolic AI and\\nSub-Symbolic AI, leading to the emergence of Neuro-Symbolic AI.\\n  Methods: The review followed the PRISMA methodology, utilizing databases such\\nas IEEE Explore, Google Scholar, arXiv, ACM, and SpringerLink. The inclusion\\ncriteria targeted peer-reviewed papers published between 2020 and 2024. Papers\\nwere screened for relevance to Neuro-Symbolic AI, with further inclusion based\\non the availability of associated codebases to ensure reproducibility.\\n  Results: From an initial pool of 1,428 papers, 167 met the inclusion criteria\\nand were analyzed in detail. The majority of research efforts are concentrated\\nin the areas of learning and inference (63%), logic and reasoning (35%), and\\nknowledge representation (44%). Explainability and trustworthiness are less\\nrepresented (28%), with Meta-Cognition being the least explored area (5%). The\\nreview identifies significant interdisciplinary opportunities, particularly in\\nintegrating explainability and trustworthiness with other research areas.\\n  Conclusion: Neuro-Symbolic AI research has seen rapid growth since 2020, with\\nconcentrated efforts in learning and inference. Significant gaps remain in\\nexplainability, trustworthiness, and Meta-Cognition. Addressing these gaps\\nthrough interdisciplinary research will be crucial for advancing the field\\ntowards more intelligent, reliable, and context-aware AI systems.',\n",
       "  'published': '2025-01-09T18:48:35Z',\n",
       "  'updated': '2025-04-05T23:53:49Z',\n",
       "  'authors': ['Brandon C. Colelough', 'William Regli'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.05435v2'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06231v1',\n",
       "  'title': 'Sustainable and Intelligent Public Facility Failure Management System\\n  Based on Large Language Models',\n",
       "  'summary': \"This paper presents a new Large Language Model (LLM)-based Smart Device\\nManagement framework, a pioneering approach designed to address the intricate\\nchallenges of managing intelligent devices within public facilities, with a\\nparticular emphasis on applications to libraries. Our framework leverages\\nstate-of-the-art LLMs to analyze and predict device failures, thereby enhancing\\noperational efficiency and reliability. Through prototype validation in\\nreal-world library settings, we demonstrate the framework's practical\\napplicability and its capacity to significantly reduce budgetary constraints on\\npublic facilities. The advanced and innovative nature of our model is evident\\nfrom its successful implementation in prototype testing. We plan to extend the\\nframework's scope to include a wider array of public facilities and to\\nintegrate it with cutting-edge cybersecurity technologies, such as Internet of\\nThings (IoT) security and machine learning algorithms for threat detection and\\nresponse. This will result in a comprehensive and proactive maintenance system\\nthat not only bolsters the security of intelligent devices but also utilizes\\nmachine learning for automated analysis and real-time threat mitigation. By\\nincorporating these advanced cybersecurity elements, our framework will be\\nwell-positioned to tackle the dynamic challenges of modern public\\ninfrastructure, ensuring robust protection against potential threats and\\nenabling facilities to anticipate and prevent failures, leading to substantial\\ncost savings and enhanced service quality.\",\n",
       "  'published': '2025-01-08T02:30:37Z',\n",
       "  'updated': '2025-01-08T02:30:37Z',\n",
       "  'authors': ['Siguo Bi', 'Jilong Zhang', 'Wei Ni'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06231v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06322v1',\n",
       "  'title': 'Multi-Agent Collaboration Mechanisms: A Survey of LLMs',\n",
       "  'summary': 'With recent advances in Large Language Models (LLMs), Agentic AI has become\\nphenomenal in real-world applications, moving toward multiple LLM-based agents\\nto perceive, learn, reason, and act collaboratively. These LLM-based\\nMulti-Agent Systems (MASs) enable groups of intelligent agents to coordinate\\nand solve complex tasks collectively at scale, transitioning from isolated\\nmodels to collaboration-centric approaches. This work provides an extensive\\nsurvey of the collaborative aspect of MASs and introduces an extensible\\nframework to guide future research. Our framework characterizes collaboration\\nmechanisms based on key dimensions: actors (agents involved), types (e.g.,\\ncooperation, competition, or coopetition), structures (e.g., peer-to-peer,\\ncentralized, or distributed), strategies (e.g., role-based or model-based), and\\ncoordination protocols. Through a review of existing methodologies, our\\nfindings serve as a foundation for demystifying and advancing LLM-based MASs\\ntoward more intelligent and collaborative solutions for complex, real-world use\\ncases. In addition, various applications of MASs across diverse domains,\\nincluding 5G/6G networks, Industry 5.0, question answering, and social and\\ncultural settings, are also investigated, demonstrating their wider adoption\\nand broader impacts. Finally, we identify key lessons learned, open challenges,\\nand potential research directions of MASs towards artificial collective\\nintelligence.',\n",
       "  'published': '2025-01-10T19:56:50Z',\n",
       "  'updated': '2025-01-10T19:56:50Z',\n",
       "  'authors': ['Khanh-Tung Tran',\n",
       "   'Dung Dao',\n",
       "   'Minh-Duong Nguyen',\n",
       "   'Quoc-Viet Pham',\n",
       "   \"Barry O'Sullivan\",\n",
       "   'Hoang D. Nguyen'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06322v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06423v1',\n",
       "  'title': 'AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written\\n  Programs',\n",
       "  'summary': 'Program synthesis has traditionally relied on human-provided specifications,\\nexamples, or prior knowledge to generate functional algorithms. Existing\\nmethods either emulate human-written algorithms or solve specific tasks without\\ngenerating reusable programmatic logic, limiting their ability to create novel\\nalgorithms. We introduce AlgoPilot, a groundbreaking approach for fully\\nautomated program synthesis without human-written programs or trajectories.\\nAlgoPilot leverages reinforcement learning (RL) guided by a Trajectory Language\\nModel (TLM) to synthesize algorithms from scratch. The TLM, trained on\\ntrajectories generated by random Python functions, serves as a soft constraint\\nduring the RL process, aligning generated sequences with patterns likely to\\nrepresent valid algorithms. Using sorting as a test case, AlgoPilot\\ndemonstrates its ability to generate trajectories that are interpretable as\\nclassical algorithms, such as Bubble Sort, while operating without prior\\nalgorithmic knowledge. This work establishes a new paradigm for algorithm\\ndiscovery and lays the groundwork for future advancements in autonomous program\\nsynthesis.',\n",
       "  'published': '2025-01-11T03:29:14Z',\n",
       "  'updated': '2025-01-11T03:29:14Z',\n",
       "  'authors': ['Xiaoxin Yin'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06423v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06442v1',\n",
       "  'title': 'ARES: Auxiliary Range Expansion for Outlier Synthesis',\n",
       "  'summary': 'Recent successes of artificial intelligence and deep learning often depend on\\nthe well-collected training dataset which is assumed to have an identical\\ndistribution with the test dataset. However, this assumption, which is called\\nclosed-set learning, is hard to meet in realistic scenarios for deploying deep\\nlearning models. As one of the solutions to mitigate this assumption, research\\non out-of-distribution (OOD) detection has been actively explored in various\\ndomains. In OOD detection, we assume that we are given the data of a new class\\nthat was not seen in the training phase, i.e., outlier, at the evaluation\\nphase. The ultimate goal of OOD detection is to detect and classify such unseen\\noutlier data as a novel \"unknown\" class. Among various research branches for\\nOOD detection, generating a virtual outlier during the training phase has been\\nproposed. However, conventional generation-based methodologies utilize\\nin-distribution training dataset to imitate outlier instances, which limits the\\nquality of the synthesized virtual outlier instance itself. In this paper, we\\npropose a novel methodology for OOD detection named Auxiliary Range Expansion\\nfor Outlier Synthesis, or ARES. ARES models the region for generating\\nout-of-distribution instances by escaping from the given in-distribution\\nregion; instead of remaining near the boundary of in-distribution region.\\nVarious stages consists ARES to ultimately generate valuable OOD-like virtual\\ninstances. The energy score-based discriminator is then trained to effectively\\nseparate in-distribution data and outlier data. Quantitative experiments on\\nbroad settings show the improvement of performance by our method, and\\nqualitative results provide logical explanations of the mechanism behind it.',\n",
       "  'published': '2025-01-11T05:44:33Z',\n",
       "  'updated': '2025-01-11T05:44:33Z',\n",
       "  'authors': ['Eui-Soo Jung',\n",
       "   'Hae-Hun Seo',\n",
       "   'Hyun-Woo Jung',\n",
       "   'Je-Geon Oh',\n",
       "   'Yoon-Yeong Kim'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06442v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06461v1',\n",
       "  'title': 'Assessing instructor-AI cooperation for grading essay-type questions in\\n  an introductory sociology course',\n",
       "  'summary': 'This study explores the use of artificial intelligence (AI) as a\\ncomplementary tool for grading essay-type questions in higher education,\\nfocusing on its consistency with human grading and potential to reduce biases.\\nUsing 70 handwritten exams from an introductory sociology course, we evaluated\\ngenerative pre-trained transformers (GPT) models\\' performance in transcribing\\nand scoring students\\' responses. GPT models were tested under various settings\\nfor both transcription and grading tasks. Results show high similarity between\\nhuman and GPT transcriptions, with GPT-4o-mini outperforming GPT-4o in\\naccuracy. For grading, GPT demonstrated strong correlations with the human\\ngrader scores, especially when template answers were provided. However,\\ndiscrepancies remained, highlighting GPT\\'s role as a \"second grader\" to flag\\ninconsistencies for assessment reviewing rather than fully replace human\\nevaluation. This study contributes to the growing literature on AI in\\neducation, demonstrating its potential to enhance fairness and efficiency in\\ngrading essay-type questions.',\n",
       "  'published': '2025-01-11T07:18:12Z',\n",
       "  'updated': '2025-01-11T07:18:12Z',\n",
       "  'authors': ['Francisco Olivos', 'Tobias Kamelski', 'Sebasti√°n Ascui-Gac'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06461v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06471v1',\n",
       "  'title': 'The Internet of Large Language Models: An Orchestration Framework for\\n  LLM Training and Knowledge Exchange Toward Artificial General Intelligence',\n",
       "  'summary': 'This paper explores the multi-dimensional challenges faced during the\\ndevelopment of Large Language Models (LLMs), including the massive scale of\\nmodel parameters and file sizes, the complexity of development environment\\nconfiguration, the singularity of model functionality, and the high costs of\\ncomputational resources. To address these challenges, this paper proposes three\\ncore technical solutions: LLM sharing protocol, LLM universal environment\\nframework, and Agent optimal path module. To solve the computational resource\\nconstraints in the early stages of research, we further innovatively propose a\\njoint mining mechanism, achieving bilateral value sharing between computing\\npower providers and model designers, including breakthrough rewards for optimal\\nmodel paths and long-term profit distribution, thereby providing researchers\\nwith cost-optimized computational resource support and promoting the continuous\\ndevelopment of LLM research and applications.',\n",
       "  'published': '2025-01-11T08:00:24Z',\n",
       "  'updated': '2025-01-11T08:00:24Z',\n",
       "  'authors': ['Wilson Wei', 'Nicholas Chen', 'Yuxuan Li'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06471v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06485v1',\n",
       "  'title': 'A Diffusive Data Augmentation Framework for Reconstruction of Complex\\n  Network Evolutionary History',\n",
       "  'summary': 'The evolutionary processes of complex systems contain critical information\\nregarding their functional characteristics. The generation time of edges\\nprovides insights into the historical evolution of various networked complex\\nsystems, such as protein-protein interaction networks, ecosystems, and social\\nnetworks. Recovering these evolutionary processes holds significant scientific\\nvalue, including aiding in the interpretation of the evolution of\\nprotein-protein interaction networks. However, existing methods are capable of\\npredicting the generation times of remaining edges given a partial temporal\\nnetwork but often perform poorly in cross-network prediction tasks. These\\nmethods frequently fail in edge generation time recovery tasks for static\\nnetworks that lack timestamps. In this work, we adopt a comparative\\nparadigm-based framework that fuses multiple networks for training, enabling\\ncross-network learning of the relationship between network structure and edge\\ngeneration times. Compared to separate training, this approach yields an\\naverage accuracy improvement of 16.98%. Furthermore, given the difficulty in\\ncollecting temporal networks, we propose a novel diffusion-model-based\\ngeneration method to produce a large number of temporal networks. By combining\\nreal temporal networks with generated ones for training, we achieve an\\nadditional average accuracy improvement of 5.46% through joint training.',\n",
       "  'published': '2025-01-11T08:39:33Z',\n",
       "  'updated': '2025-01-11T08:39:33Z',\n",
       "  'authors': ['En Xu', 'Can Rong', 'Jingtao Ding', 'Yong Li'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06485v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06561v2',\n",
       "  'title': 'Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for\\n  Mid-term Human Mobility Prediction',\n",
       "  'summary': \"Predicting individual mobility patterns is crucial across various\\napplications. While current methods mainly focus on predicting the next\\nlocation for personalized services like recommendations, they often fall short\\nin supporting broader applications such as traffic management and epidemic\\ncontrol, which require longer period forecasts of human mobility. This study\\naddresses mid-term mobility prediction, aiming to capture daily travel patterns\\nand forecast trajectories for the upcoming day or week. We propose a novel\\nMulti-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to\\nefficiently extract spatial and temporal information by decoupling daily\\ntrajectories into distinct location-duration chains. Our approach employs a\\nhierarchical encoder to model multi-scale temporal patterns, including daily\\nrecurrence and weekly periodicity, and utilizes a transformer-based decoder to\\nglobally attend to predicted information in the location or duration chain.\\nAdditionally, we introduce a spatial heterogeneous graph learner to capture\\nmulti-scale spatial relationships, enhancing semantic-rich representations.\\nExtensive experiments, including statistical physics analysis, are conducted on\\nlarge-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay\\nArea, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to\\nepidemic modeling in Boston, MSTDP significantly outperforms the\\nbest-performing baseline, achieving a remarkable 62.8% reduction in MAE for\\ncumulative new cases.\",\n",
       "  'published': '2025-01-11T14:41:47Z',\n",
       "  'updated': '2025-08-19T14:26:55Z',\n",
       "  'authors': ['Zongyuan Huang',\n",
       "   'Weipeng Wang',\n",
       "   'Shaoyu Huang',\n",
       "   'Marta C. Gonzalez',\n",
       "   'Yaohui Jin',\n",
       "   'Yanyan Xu'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06561v2'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06577v1',\n",
       "  'title': 'Transforming Social Science Research with Transfer Learning: Social\\n  Science Survey Data Integration with AI',\n",
       "  'summary': 'Large-N nationally representative surveys, which have profoundly shaped\\nAmerican politics scholarship, represent related but distinct domains -a key\\ncondition for transfer learning applications. These surveys are related through\\ntheir shared demographic, party identification, and ideological variables, yet\\ndiffer in that individual surveys often lack specific policy preference\\nquestions that researchers require. Our study introduces a novel application of\\ntransfer learning (TL) to address these gaps, marking the first systematic use\\nof TL paradigms in the context of survey data. Specifically, models pre-trained\\non the Cooperative Election Study (CES) dataset are fine-tuned for use in the\\nAmerican National Election Studies (ANES) dataset to predict policy questions\\nbased on demographic variables. Even with a naive architecture, our transfer\\nlearning approach achieves approximately 92 percentage accuracy in predicting\\nmissing variables across surveys, demonstrating the robust potential of this\\nmethod. Beyond this specific application, our paper argues that transfer\\nlearning is a promising framework for maximizing the utility of existing survey\\ndata. We contend that artificial intelligence, particularly transfer learning,\\nopens new frontiers in social science methodology by enabling systematic\\nknowledge transfer between well-administered surveys that share common\\nvariables but differ in their outcomes of interest.',\n",
       "  'published': '2025-01-11T16:01:44Z',\n",
       "  'updated': '2025-01-11T16:01:44Z',\n",
       "  'authors': ['Ali Amini'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06577v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06598v3',\n",
       "  'title': 'ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code\\n  Generation',\n",
       "  'summary': 'Multimodal Large Language Models (MLLMs) have demonstrated remarkable\\ncapabilities in chart understanding tasks. However, interpreting charts with\\ntextual descriptions often leads to information loss, as it fails to fully\\ncapture the dense information embedded in charts. In contrast, parsing charts\\ninto code provides lossless representations that can effectively contain all\\ncritical details. Although existing open-source MLLMs have achieved success in\\nchart understanding tasks, they still face two major challenges when applied to\\nchart-to-code tasks: (1) Low executability and poor restoration of chart\\ndetails in the generated code and (2) Lack of large-scale and diverse training\\ndata. To address these challenges, we propose \\\\textbf{ChartCoder}, the first\\ndedicated chart-to-code MLLM, which leverages Code LLMs as the language\\nbackbone to enhance the executability of the generated code. Furthermore, we\\nintroduce \\\\textbf{Chart2Code-160k}, the first large-scale and diverse dataset\\nfor chart-to-code generation, and propose the \\\\textbf{Snippet-of-Thought (SoT)}\\nmethod, which transforms direct chart-to-code generation data into step-by-step\\ngeneration. Experiments demonstrate that ChartCoder, with only 7B parameters,\\nsurpasses existing open-source MLLMs on chart-to-code benchmarks, achieving\\nsuperior chart restoration and code excitability. Our code is available at\\nhttps://github.com/thunlp/ChartCoder.',\n",
       "  'published': '2025-01-11T17:52:22Z',\n",
       "  'updated': '2025-07-02T04:47:37Z',\n",
       "  'authors': ['Xuanle Zhao',\n",
       "   'Xianzhen Luo',\n",
       "   'Qi Shi',\n",
       "   'Chi Chen',\n",
       "   'Shuo Wang',\n",
       "   'Zhiyuan Liu',\n",
       "   'Maosong Sun'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06598v3'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06625v1',\n",
       "  'title': 'Guided Code Generation with LLMs: A Multi-Agent Framework for Complex\\n  Code Tasks',\n",
       "  'summary': \"Large Language Models (LLMs) have shown remarkable capabilities in code\\ngeneration tasks, yet they face significant limitations in handling complex,\\nlong-context programming challenges and demonstrating complex compositional\\nreasoning abilities. This paper introduces a novel agentic framework for\\n``guided code generation'' that tries to address these limitations through a\\ndeliberately structured, fine-grained approach to code generation tasks. Our\\nframework leverages LLMs' strengths as fuzzy searchers and approximate\\ninformation retrievers while mitigating their weaknesses in long sequential\\nreasoning and long-context understanding. Empirical evaluation using OpenAI's\\nHumanEval benchmark with Meta's Llama 3.1 8B model (int4 precision)\\ndemonstrates a 23.79\\\\% improvement in solution accuracy compared to direct\\none-shot generation. Our results indicate that structured, guided approaches to\\ncode generation can significantly enhance the practical utility of LLMs in\\nsoftware development while overcoming their inherent limitations in\\ncompositional reasoning and context handling.\",\n",
       "  'published': '2025-01-11T19:21:53Z',\n",
       "  'updated': '2025-01-11T19:21:53Z',\n",
       "  'authors': ['Amr Almorsi', 'Mohanned Ahmed', 'Walid Gomaa'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06625v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06628v1',\n",
       "  'title': 'Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs\\n  with LLMs: A Neuro-Symbolic Approach',\n",
       "  'summary': 'This paper introduces a neuro-symbolic approach for relational exploration in\\ncultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for\\nexplanation generation and a novel mathematical framework to quantify the\\ninterestingness of relationships. We demonstrate the importance of\\ninterestingness measure using a quantitative analysis, by highlighting its\\nimpact on the overall performance of our proposed system, particularly in terms\\nof precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked\\nOpen Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of\\n0.68, and an F1-score of 0.69, representing an improvement compared to\\ngraph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based\\nbaselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our\\nLLM-powered explanations exhibit better quality, reflected in BLEU (0.52),\\nROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline\\napproaches. We show a strong correlation (0.65) between interestingness measure\\nand the quality of generated explanations, validating its effectiveness. The\\nfindings highlight the importance of LLMs and a mathematical formalization for\\ninterestingness in enhancing the effectiveness of relational exploration in\\ncultural heritage knowledge graphs, with results that are measurable and\\ntestable. We further show that the system enables more effective exploration\\ncompared to purely knowledge-based and graph-based methods.',\n",
       "  'published': '2025-01-11T19:50:09Z',\n",
       "  'updated': '2025-01-11T19:50:09Z',\n",
       "  'authors': ['Mohammed Maree'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06628v1'},\n",
       " {'id': 'http://arxiv.org/abs/2501.06642v1',\n",
       "  'title': 'Common Sense Is All You Need',\n",
       "  'summary': 'Artificial intelligence (AI) has made significant strides in recent years,\\nyet it continues to struggle with a fundamental aspect of cognition present in\\nall animals: common sense. Current AI systems, including those designed for\\ncomplex tasks like autonomous driving, problem-solving challenges such as the\\nAbstraction and Reasoning Corpus (ARC), and conversational benchmarks like the\\nTuring Test, often lack the ability to adapt to new situations without\\nextensive prior knowledge. This manuscript argues that integrating common sense\\ninto AI systems is essential for achieving true autonomy and unlocking the full\\nsocietal and commercial value of AI.\\n  We propose a shift in the order of knowledge acquisition emphasizing the\\nimportance of developing AI systems that start from minimal prior knowledge and\\nare capable of contextual learning, adaptive reasoning, and embodiment -- even\\nwithin abstract domains. Additionally, we highlight the need to rethink the AI\\nsoftware stack to address this foundational challenge. Without common sense, AI\\nsystems may never reach true autonomy, instead exhibiting asymptotic\\nperformance that approaches theoretical ideals like AIXI but remains\\nunattainable in practice due to infinite resource and computation requirements.\\n  While scaling AI models and passing benchmarks like the Turing Test have\\nbrought significant advancements in applications that do not require autonomy,\\nthese approaches alone are insufficient to achieve autonomous AI with common\\nsense. By redefining existing benchmarks and challenges to enforce constraints\\nthat require genuine common sense, and by broadening our understanding of\\nembodiment to include both physical and abstract domains, we can encourage the\\ndevelopment of AI systems better equipped to handle the complexities of\\nreal-world and abstract environments.',\n",
       "  'published': '2025-01-11T21:23:41Z',\n",
       "  'updated': '2025-01-11T21:23:41Z',\n",
       "  'authors': ['Hugo Latapie'],\n",
       "  'pdf_link': 'http://arxiv.org/pdf/2501.06642v1'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea10a47",
   "metadata": {},
   "source": [
    "#### Download PDF files of the papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a3d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, filename):\n",
    "    \"\"\"Download PDF from URL and save to file\"\"\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"PDF saved as {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6339a281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF saved as ../../data/arxiv_papers/2501.00750v2.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.01149v2.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.01349v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.01835v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.02725v4.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.03824v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.05435v2.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06231v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06322v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06423v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06442v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06461v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06471v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06485v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06561v2.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06577v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06598v3.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06625v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06628v1.pdf\n",
      "PDF saved as ../../data/arxiv_papers/2501.06642v1.pdf\n"
     ]
    }
   ],
   "source": [
    "for paper in papers:\n",
    "    path = f\"../../data/arxiv_papers/{paper['pdf_link'].split('/')[-1]}.pdf\"\n",
    "    download_pdf(paper['pdf_link'], path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90154272",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Metadata of Arxiv Papers\n",
    "import json\n",
    "with open('../../data/arxiv_papers/metadata.json', 'w') as f:\n",
    "    json.dump(papers, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aieng-bootcamp-defaut",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
